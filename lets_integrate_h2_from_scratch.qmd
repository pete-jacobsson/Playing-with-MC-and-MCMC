---
title: "Lets integrate a binary enthropy function with MC"
author: "Piotr Jacobsson"
format: html
editor: visual
---

##TO DO: Make this Corbel/Cambria

I picked up the binary entropy function from MacKay's 2003 classic *Information Theory, Inference, and Learning Algorithms*, where it is used to derive approximations for combinations in evaluating the probabilities of error in different repetition codes (basically codes that rely on transmitting the same bit multiple times to minimize risk of transmission errors).

The formula for the function looks like this(MacKay 2003: 2): 
$$
H_2(x) = xlog \frac{1}{x} + (1 - x)log \frac{1}{1-x}
$$

What I want to do here is to build an Monte Carlo rejection sampler to integrate the function. However, before getting to building the sampler, lets first write a function for the binary entropy function and plot the beast.

```{r}
### Binary entropy function.
### This function takes on an x between zero and one and returns the H2(x) of this value

h2x <- function (x){
  x * log2(1/x) + (1-x) * log2(1/(1-x)) #Note that the binary entropy function 
}

h2x_df <- data.frame(x = seq(0.01, 0.99, 0.01), h2x = h2x(seq(0.01, 0.99, 0.01)))

library(ggplot2)

ggplot(h2x_df, aes(x = x, y = h2x)) +
  geom_line() +
  theme_bw() +
  labs(
    title = "Binary entropy function",
  ) +
  ylab(bquote(H[2](x)))


```

As we can see the function forms an arc that starts at zero, ends at one and has a maximum value of one. This maximum value will prove helpful when building the rejection sampler.

## The sampler
Now that we know what the function looks like, lets build the sampler. Lets iterate the design a little. In the first stage, we will just write out the code that gives us the result.To make things a little more interesting, we will try to use purr iterations rather than traditional for loops. Next we'll wrap it into a function. Last, we'll modify the function, so that it can take on single variable function as an input.

OK, so lets get onto the first step. Building the sampler itself.

```{r}
library(dplyr)
library(purrr)

##First set up a base DF, with 10000 sims.

sampler_results <- data.frame(x_vals = runif(10000, 0, 1), 
                              y_vals = runif(10000, 0, 1)) %>%
  ##Next check if the values are less than the H2(x) values
  mutate(
    h2x_vals = h2x(x_vals),
    less_h2x = if_else(y_vals <= h2x_vals, TRUE, FALSE) #I broke this up into two steps, so I can check if the intermediate steps work the way they should :)
  )


```

As the area covered by the box equals to one, the ratio of dots "under" the curve to the total number of dots generated is the actual result.

```{r}

area_under_curve <- sampler_results %>%
  summarize(
    n_total = n(),
    under_curve = sum(less_h2x),
    area = under_curve / n_total
  ) %>%
  pull(area)

area_under_curve

```

We can also visualize the area by plotting the individual dots passed to the sampler:
```{r}
sampler_results %>%
  ggplot(aes(x = x_vals, y = y_vals, color = less_h2x)) +
  geom_point() +
  theme_classic()
```

So the sampler is working. Now lets turn it into a function, so we can begin exploring it further.

```{r}
h2x_sampler <- function (x1, x2, n_sims){
  ### Takes on values of x and returns the H2(x) integral between those values.
  ### Assumes x1 < x2 and 0 < x1, x2 < 1
  
  
  sampler_results <- data.frame(x_vals = runif(n_sims, x1, x2), 
                              y_vals = runif(n_sims, 0, 1)) %>%
  ##Next check if the values are less than the H2(x) values
  mutate(
    h2x_vals = h2x(x_vals),
    less_h2x = if_else(y_vals <= h2x_vals, TRUE, FALSE) #I broke this up into two steps, so I can check if the intermediate steps work the way they should :)
  )
  
  sampler_results
}


#Run a visual test

h2x_sampler(0.3, 0.8, 100) %>%
  ggplot(aes(x = x_vals, y = y_vals, color = less_h2x)) +
  geom_point() +
  theme_classic()

h2x_sampler(0.3, 0.8, 100000) %>%
  ggplot(aes(x = x_vals, y = y_vals, color = less_h2x)) +
  geom_point() +
  theme_classic()

```





